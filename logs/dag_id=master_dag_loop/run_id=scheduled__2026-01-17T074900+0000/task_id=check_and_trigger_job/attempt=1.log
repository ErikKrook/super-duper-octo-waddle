[2026-01-17T07:51:02.946+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2026-01-17T07:51:03.036+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: master_dag_loop.check_and_trigger_job scheduled__2026-01-17T07:49:00+00:00 [queued]>
[2026-01-17T07:51:03.051+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: master_dag_loop.check_and_trigger_job scheduled__2026-01-17T07:49:00+00:00 [queued]>
[2026-01-17T07:51:03.052+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2026-01-17T07:51:03.070+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): check_and_trigger_job> on 2026-01-17 07:49:00+00:00
[2026-01-17T07:51:03.082+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'master_dag_loop', 'check_and_trigger_job', 'scheduled__2026-01-17T07:49:00+00:00', '--job-id', '53', '--raw', '--subdir', 'DAGS_FOLDER/MasterDagLoop.py', '--cfg-path', '/tmp/tmpsytluaay']
[2026-01-17T07:51:03.087+0000] {standard_task_runner.py:91} INFO - Job 53: Subtask check_and_trigger_job
[2026-01-17T07:51:03.088+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62 DeprecationWarning: This process (pid=1709) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2026-01-17T07:51:03.091+0000] {standard_task_runner.py:64} INFO - Started process 1712 to run task
[2026-01-17T07:51:03.197+0000] {task_command.py:426} INFO - Running <TaskInstance: master_dag_loop.check_and_trigger_job scheduled__2026-01-17T07:49:00+00:00 [running]> on host 6fa7644da444
[2026-01-17T07:51:03.332+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='master_dag_loop' AIRFLOW_CTX_TASK_ID='check_and_trigger_job' AIRFLOW_CTX_EXECUTION_DATE='2026-01-17T07:49:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2026-01-17T07:49:00+00:00'
[2026-01-17T07:51:03.334+0000] {taskinstance.py:430} INFO - ::endgroup::
[2026-01-17T07:51:03.380+0000] {base.py:84} INFO - Using connection ID 'postgres_con' for task execution.
[2026-01-17T07:51:03.392+0000] {sql.py:495} INFO - Running statement: 
    SELECT job_id, dag_id 
    FROM job_control_queue 
    WHERE is_ready = TRUE 
    ORDER BY job_id ASCL
    IMIT 1
    , parameters: None
[2026-01-17T07:51:03.394+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2026-01-17T07:51:03.396+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/MasterDagLoop.py", line 23, in trigger_generator
    job = get_ready_job()
          ^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/MasterDagLoop.py", line 19, in get_ready_job
    records = hook.get_records(sql)
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 309, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 442, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 500, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "ASCL"
LINE 5:     ORDER BY job_id ASCL
                            ^

[2026-01-17T07:51:03.430+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=master_dag_loop, task_id=check_and_trigger_job, run_id=scheduled__2026-01-17T07:49:00+00:00, execution_date=20260117T074900, start_date=20260117T075103, end_date=20260117T075103
[2026-01-17T07:51:03.451+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 53 for task check_and_trigger_job (syntax error at or near "ASCL"
LINE 5:     ORDER BY job_id ASCL
                            ^
; 1712)
[2026-01-17T07:51:03.470+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2026-01-17T07:51:03.503+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2026-01-17T07:51:03.506+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
